# pyright: reportUnknownVariableType=false, reportUnknownMemberType=false
"""
Script de an√°lise de relat√≥rios de linters (Ruff, Flake8, Pyright).
Agrupa issues por arquivo e classifica em grupos A/B/C para facilitar triagem.

Uso: Execute a partir da raiz do projeto com:
    python devtools/qa/analyze_linters.py
"""

import json
from collections import Counter, defaultdict
from pathlib import Path
from typing import Any, DefaultDict, Dict, List, Tuple

# Type aliases para clareza
JsonObj = Dict[str, Any]
IssueInfo = Dict[str, Any]
GrupoIssues = List[Tuple[str, List[IssueInfo]]]

# Determinar diret√≥rio dos relat√≥rios (mesmo diret√≥rio do script)
SCRIPT_DIR = Path(__file__).parent
RUFF_JSON = SCRIPT_DIR / "ruff.json"
FLAKE8_TXT = SCRIPT_DIR / "flake8.txt"

# An√°lise Ruff
print("=" * 80)
print("AN√ÅLISE RUFF.JSON")
print("=" * 80)

# Detectar encoding automaticamente (ruff pode gerar UTF-8 ou UTF-16)
try:
    with open(RUFF_JSON, encoding="utf-8") as f:
        ruff_data: List[JsonObj] = json.load(f)
except UnicodeDecodeError:
    with open(RUFF_JSON, encoding="utf-16") as f:
        ruff_data = json.load(f)

print(f"\nTotal issues Ruff: {len(ruff_data)}\n")

# Agrupar por c√≥digo
ruff_by_code: Counter[str] = Counter(d["code"] for d in ruff_data)
print("Issues por c√≥digo:")
for code, count in ruff_by_code.most_common():
    print(f"  {code}: {count}x")

# Agrupar por arquivo
ruff_by_file: DefaultDict[str, List[IssueInfo]] = defaultdict(list)
for issue in ruff_data:
    filename: str = issue["filename"].replace("\\", "/").split("/")[-1]
    filepath: str = issue["filename"].replace("\\", "/")
    ruff_by_file[filepath].append(
        {"code": issue["code"], "line": issue["location"]["row"], "message": issue["message"]}
    )

print("\n" + "=" * 80)
print("CLASSIFICA√á√ÉO POR GRUPO")
print("=" * 80)

grupo_a: GrupoIssues = []  # tests/, scripts/
grupo_b: GrupoIssues = []  # app seguro
grupo_c: GrupoIssues = []  # sens√≠vel

for filepath, issues in ruff_by_file.items():
    is_test: bool = "tests/" in filepath or "test_" in filepath
    is_script: bool = "scripts/" in filepath

    if is_test or is_script:
        grupo_a.append((filepath, issues))
    else:
        # Verificar se √© F841 √≥bvio
        all_f841: bool = all(i["code"] == "F841" for i in issues)
        if all_f841 and len(issues) <= 2:
            grupo_b.append((filepath, issues))
        else:
            grupo_c.append((filepath, issues))

print(f"\nüìÅ GRUPO A (tests/scripts): {len(grupo_a)} arquivos")
for path, issues in grupo_a:
    print(f"  {path.split('/')[-1]}: {len(issues)} issues")
    for iss in issues[:3]:
        print(f"    L{iss['line']}: {iss['code']} - {iss['message'][:60]}")

print(f"\nüìÅ GRUPO B (app seguro): {len(grupo_b)} arquivos")
for path, issues in grupo_b:
    print(f"  {path.split('/')[-1]}: {len(issues)} issues")
    for iss in issues:
        print(f"    L{iss['line']}: {iss['code']} - {iss['message'][:60]}")

print(f"\n‚ö†Ô∏è  GRUPO C (sens√≠vel/n√£o tocar): {len(grupo_c)} arquivos")
for path, issues in grupo_c:
    print(f"  {path.split('/')[-1]}: {len(issues)} issues")

# An√°lise Flake8
print("\n" + "=" * 80)
print("AN√ÅLISE FLAKE8.TXT")
print("=" * 80)

if not FLAKE8_TXT.exists():
    print("\nRelatÔøΩÔøΩrio flake8.txt n«úo encontrado (Flake8 foi aposentado em favor do Ruff).")
    print("Gere o arquivo manualmente apenas se estiver revisando histÔøΩÔøΩrico legado.")
else:
    # Detectar encoding automaticamente (flake8 pode gerar UTF-8 ou UTF-16)
    try:
        with open(FLAKE8_TXT, encoding="utf-8") as f:
            flake8_lines: List[str] = [line.strip() for line in f.readlines() if line.strip()]
    except UnicodeDecodeError:
        with open(FLAKE8_TXT, encoding="utf-16") as f:
            flake8_lines = [line.strip() for line in f.readlines() if line.strip()]

    print(f"\nTotal issues Flake8: {len(flake8_lines)}\n")

    # Amostra
    print("Primeiras 10 issues:")
    for line in flake8_lines[:10]:
        print(f"  {line[:100]}")
